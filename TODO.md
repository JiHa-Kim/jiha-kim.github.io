

## Legend 
x=done
*=revise
(no prefix)=not started

## Crash courses

- x Linear Algebra  
  └─ x Multivariable Calculus  
      ├─ x Functional Analysis & Matrix Norms  
      │   ├─ * Tensor Calculus  
      │   │   ├─ x Differential Geometry  
      │   │   └─ x Statistics and Information Theory  
      │   │       └─ Information Geometry (requires both above)  
      │   └─ x Variational Calculus  
      │       └─ x Convex Analysis  
      │           └─ x Online Learning  
      └─ x Numerical Analysis  

## Series

x 1. Introduction to basic mathematical optimization
x 2. Iterative methods: gradient-free vs. gradient-based optimization
x 3. Desirable properties of optimizers
x 4. Speedrun of common gradient-based ML optimizers
x 5. Problem formalization
x 6. Gradient descent and gradient flow
x 7. Challenges of high-dimensional non-convex optimization in deep learning
x 8. Stochastic Gradient Descent and effects of randomness
x 9. Adaptive methods and preconditioning
x 10. Momentum
x 11. Soft inductive biases (regularization)
x 12. Adam optimizer, info geo view: diagonal Fisher information approximation
x 13. Adam optimizer, online learning view: Discounted Follow-The-Regularized-Leader
14. Metrized deep learning (Iso/IsoAdam, Shampoo, Muon)
15. Parameter-free optimization